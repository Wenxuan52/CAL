general:
  hidden_size: 256
  actor_hidden_layers: [256, 256]
  actor_lr: 0.0003
  critic_lr: 0.0003
  safety_critic_lr: 0.0003
  exploration_noise_std: 0.2
  noise_clip: 0.5
  policy_target_update_frequency: 2
  critic_target_update_frequency: 2
  tau: 0.005
  qc_ens_size: 1
  k: 1.0
  c: 0.0
  min_pool_size: 5000
  num_train_repeat: 1
  max_train_repeat_per_step: 1
  policy_train_batch_size: 256
  init_exploration_steps: 1000
  replay_size: 1000000
  dem_action_noise_decay: 1.0
  dem_action_noise_min: 0.05
  dem_log_std_clip: [-5.0, 2.0]
  dem_use_entropy_regularization: false
  dem_entropy_coef: 0.0
  dem_lam_lr: 0.0003
  dem_actor_weight_decay: 0.0
  dem_exploration_schedule:
    type: linear
    initial: 0.2
    final: 0.05
    steps: 150000
  dem_noise_schedule:
    type: geometric
    beta: 1.0
    sigma_min: 0.1
    sigma_max: 1.0
    power: 2.0
  dem_score_hidden_size: 256
  dem_score_hidden_layers: 3
  dem_score_time_layers: 2
  dem_score_lr: 0.0003
  dem_num_integration_steps: 32
  dem_time_range: 1.0
  dem_prior_std: 1.0
  dem_diffusion_scale: 1.0
  dem_eval_diffusion_scale: 0.0
  dem_lambda_epsilon: 0.001
  dem_negative_time: false
  dem_negative_time_steps: 0
  dem_energy_regularization: 0.0
  dem_action_penalty: 0.0
  device: cuda
  grad_clip_norm: null
  policy_update_delay: 2
  deterministic_eval: true

environments:
  Safexp-CarButton1-v0:
    exploration_noise_std: 0.3
    dem_exploration_schedule:
      type: linear
      initial: 0.3
      final: 0.05
      steps: 200000
    init_exploration_steps: 1000
    min_pool_size: 5000
  Safexp-PointButton1-v0:
    exploration_noise_std: 0.25
    dem_exploration_schedule:
      type: linear
      initial: 0.25
      final: 0.05
      steps: 150000
